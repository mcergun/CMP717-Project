
@misc{Authors14,
 author = {Authors},
 title = {The frobnicatable foo filter},
 note = {Face and Gesture  submission ID 324. Supplied as additional material {\tt fg324.pdf}},
 year = 2014
}

@misc{Authors14b,
 author = {Authors},
 title = {Frobnication tutorial},
 note = {Supplied as additional material {\tt tr.pdf}},
 year = 2014
}

@article{Alpher02,
author = {A. Alpher},
title = {Frobnication},
journal = {Journal of Foo},
volume = 12, 
number = 1, 
pages = {234--778}, 
year = 2002
}

@article{Alpher03,
author = {A. Alpher and  J.~P.~N. Fotheringham-Smythe},
title = {Frobnication revisited},
journal = {Journal of Foo},
volume = 13, 
number = 1, 
pages = {234--778}, 
year = 2003
}

@article{Alpher04,
author = {A. Alpher and J.~P.~N. Fotheringham-Smythe and G. Gamow},
title = {Can a machine frobnicate?},
journal = {Journal of Foo},
volume = 14, 
number = 1, 
pages = {234--778}, 
year = 2004
}

@InProceedings{ham2015,
	author = {Bumsub Ham and Minsu Cho and Jean Ponce},
	title = {Robust Image Filtering using Joint Static and Dynamic Guidance},
	booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
	year = {2015}
}

@article{triclobs,
	abstract = {{The fusion and enhancement of multiband nighttime imagery for surveillance and navigation has been the subject of extensive research for over two decades. Despite the ongoing efforts in this area there is still only a small number of static multiband test images available for the development and evaluation of new image fusion and enhancement methods. Moreover, dynamic multiband imagery is also currently lacking. To fill this gap we present the TRICLOBS dynamic multi-band image data set containing sixteen registered visual (0.4–0.7μm), near-infrared (NIR, 0.7–1.0μm) and long-wave infrared (LWIR, 8–14μm) motion sequences. They represent different military and civilian surveillance scenarios registered in three different scenes. Scenes include (military and civilian) people that are stationary, walking or running, or carrying various objects. Vehicles, foliage, and buildings or other man-made structures are also included in the scenes. This data set is primarily intended for the development and evaluation of image fusion, enhancement and color mapping algorithms for short-range surveillance applications. The imagery was collected during several field trials with our newly developed TRICLOBS (TRI-band Color Low-light OBServation) all-day all-weather surveillance system. This system registers a scene in the Visual, NIR and LWIR part of the electromagnetic spectrum using three optically aligned sensors (two digital image intensifiers and an uncooled long-wave infrared microbolometer). The three sensor signals are mapped to three individual RGB color channels, digitized, and stored as uncompressed RGB (false) color frames. The TRICLOBS data set enables the development and evaluation of (both static and dynamic) image fusion, enhancement and color mapping algorithms. To allow the development of realistic color remapping procedures, the data set also contains color photographs of each of the three scenes. The color statistics derived from these photographs can be used to define color mappings that give the multi-band imagery a realistic color appearance.}},
	author = {Toet, Alexander and Hogervorst, Maarten A. and Pinkus, Alan R.},
	citeulike-article-id = {14343265},
	citeulike-linkout-0 = {http://dx.doi.org/10.1371/journal.pone.0165016},
	day = {30},
	doi = {10.1371/journal.pone.0165016},
	journal = {PLOS ONE},
	month = dec,
	number = {12},
	pages = {e0165016+},
	posted-at = {2017-04-23 14:05:56},
	priority = {2},
	publisher = {Public Library of Science},
	title = {{The TRICLOBS Dynamic Multi-Band Image Data Set for the Development and Evaluation of Image Fusion Methods}},
	url = {http://dx.doi.org/10.1371/journal.pone.0165016},
	volume = {11},
	year = {2016}
}

